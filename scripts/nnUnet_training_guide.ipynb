{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model using the nnUnet library \n",
    "see https://github.com/MIC-DKFZ/nnUNet/tree/master\n",
    "\n",
    "1 - Convert a subset the competition dataset to nnunet format\n",
    "2 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnunet_dataset_name = \"Dataset007_AMOS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import config\n",
    "import os\n",
    "nnunet_train_dir = os.path.join(config[\"DATA_DIR\"], \"nnunet_raw\", nnunet_dataset_name)\n",
    "os.makedirs(nnunet_train_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"imagesTr\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"imagesTs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"labelsTr\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"labelsTs\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# or full dataset\\nfiles = [os.path.join(dp, f) for dp, dn, filenames in os.walk(os.path.join(config[\"DATA_DIR\"], \"3D_train_npz_random_10percent_16G\")) for f in filenames if os.path.splitext(f)[1] == \\'.npz\\']\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use only a subdir\n",
    "\n",
    "subset_name = \"CT/CT_AMOS\" # using a subset for now\n",
    "train_dir = os.path.join(config[\"DATA_DIR\"], \"3D_train_npz_random_10percent_16G\", subset_name)\n",
    "files = [os.path.join(train_dir,f) for f in os.listdir(train_dir) if os.path.splitext(f)[1] == '.npz']\n",
    "\"\"\"\n",
    "# or full dataset\n",
    "files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(os.path.join(config[\"DATA_DIR\"], \"3D_train_npz_random_10percent_16G\")) for f in filenames if os.path.splitext(f)[1] == '.npz']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)\n",
    "#files = files[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (59, 512, 512)\n",
      "shape: (76, 512, 512)\n",
      "shape: (66, 512, 512)\n",
      "shape: (61, 512, 512)\n",
      "spacing: [0.78200001 0.78200001 5.        ]spacing: [0.97265625 0.97265625 5.        ]spacing: [0.78200001 0.78200001 5.        ]\n",
      "spacing: [0.78200001 0.78200001 5.        ]\n",
      "\n",
      "\n",
      "shape: (73, 512, 512)\n",
      "spacing: [0.90399998 0.90399998 5.        ]\n",
      "shape: (58, 768, 768)\n",
      "spacing: [0.65104169 0.65104169 5.        ]\n",
      "shape: (105, 512, 512)\n",
      "spacing: [0.83099997 0.83099997 5.        ]\n",
      "shape: (108, 512, 512)\n",
      "spacing: [0.75585902 0.75585902 2.5       ]\n",
      "shape: (77, 512, 512)\n",
      "spacing: [0.72265625 0.72265625 5.        ]\n",
      "shape: (58, 768, 768)\n",
      "spacing: [0.5703125 0.5703125 5.       ]\n",
      "shape: (118, 512, 512)\n",
      "spacing: [0.63085902 0.63085902 2.5       ]\n",
      "shape: (88, 768, 768)\n",
      "spacing: [0.5078125 0.5078125 5.       ]\n",
      "shape: (111, 512, 512)\n",
      "spacing: [0.67578125 0.67578125 5.        ]\n",
      "shape: (147, 512, 512)\n",
      "spacing: [0.5703125 0.5703125 2.       ]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "shape: (161, 512, 512)\n",
      "spacing: [0.77148438 0.77148438 2.        ]\n",
      "shape: (59, 768, 768)\n",
      "spacing: [0.47265625 0.47265625 5.        ]\n",
      "shape: (139, 512, 512)\n",
      "spacing: [0.71875 0.71875 2.     ]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "shape: (260, 512, 512)\n",
      "spacing: [0.703125 0.703125 1.25    ]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "shape: (51, 768, 768)\n",
      "spacing: [0.48307291 0.48307291 5.        ]\n",
      "shape: (57, 512, 512)\n",
      "spacing: [0.82700002 0.82700002 5.        ]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "shape: (61, 768, 768)\n",
      "spacing: [0.52473956 0.52473956 5.        ]\n",
      "shape: (57, 768, 768)\n",
      "spacing: [0.44791666 0.44791666 5.        ]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "shape: (96, 512, 512)\n",
      "spacing: [0.59765625 0.59765625 5.        ]\n",
      "shape: (89, 768, 768)\n",
      "spacing: [0.64583331 0.64583331 5.        ]\n",
      "shape: (101, 512, 512)\n",
      "spacing: [0.78200001 0.78200001 5.        ]\n",
      "[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "shape: (63, 768, 768)\n",
      "spacing: [0.65104169 0.65104169 5.        ]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "shape: (142, 512, 512)\n",
      "shape: (158, 512, 512)\n",
      "spacing: [0.58398438 0.58398438 2.        ]\n",
      "spacing: [0.765625 0.765625 2.      ]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "shape: (71, 768, 768)\n",
      "spacing: [0.46223959 0.46223959 5.        ]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "shape: (62, 768, 768)\n",
      "spacing: [0.609375 0.609375 5.      ]\n",
      "[ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Processed 30 files successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "def process_file(file_info, train_dir, nnunet_train_dir, total_files):\n",
    "    i, file = file_info\n",
    "    subset = \"Tr\" if i < total_files * 0.8 else \"Ts\"\n",
    "    #print(f\"file : {os.path.basename(file)}, {i}/{total_files}\")\n",
    "    \n",
    "    data = np.load( file, allow_pickle=True)\n",
    "    imgs = data[\"imgs\"]\n",
    "    spacing = data[\"spacing\"]\n",
    "    print(f\"shape: {imgs.shape}\")\n",
    "    print(f\"spacing: {spacing}\")\n",
    "    spacing = spacing[2], spacing[1], spacing[0]  # Adjusting to match NIfTI format (z, y, x)\n",
    "    \n",
    "    # Create affine matrix\n",
    "    affine = np.eye(4)\n",
    "    affine[0, 0] = data[\"spacing\"][0]\n",
    "    affine[1, 1] = data[\"spacing\"][1]\n",
    "    affine[2, 2] = data[\"spacing\"][2]\n",
    "    \n",
    "    # Save images\n",
    "    nib_img = nib.Nifti1Image(imgs, affine=affine)\n",
    "    nib.save(nib_img, os.path.join(nnunet_train_dir, \"images\"+subset, os.path.basename(file).replace(\".npz\", \"_0000.nii.gz\")))\n",
    "    \n",
    "    # Process and save ground truth\n",
    "    gts = data[\"gts\"]\n",
    "    print(np.unique(gts))\n",
    "    #gts = (gts == 1).astype(np.int8)\n",
    "    nib_gt = nib.Nifti1Image(gts, affine=affine)\n",
    "    nib.save(nib_gt, os.path.join(nnunet_train_dir, \"labels\"+subset, os.path.basename(file).replace(\".npz\", \".nii.gz\")))\n",
    "    \n",
    "    return file\n",
    "\n",
    "# Main execution\n",
    "# Create list of (index, filename) tuples\n",
    "file_list = [(i, file) for i, file in enumerate(files)]\n",
    "\n",
    "# Create partial function with fixed arguments\n",
    "process_func = partial(process_file, \n",
    "                      train_dir=train_dir, \n",
    "                      nnunet_train_dir=nnunet_train_dir, \n",
    "                      total_files=len(files))\n",
    "\n",
    "# Use 14 cores (leave 2 for system)\n",
    "with Pool(processes=14) as pool:\n",
    "    results = pool.map(process_func, file_list)\n",
    "\n",
    "print(f\"Processed {len(results)} files successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (66, 512, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff33ea76fc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa4AAAGiCAYAAAC/NyLhAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJ7RJREFUeJzt3XtwVGWC9/Hf6e5059odEkg3EYI4Khi5uAMaeu4rWSKTcXXFKseiHHaWGks2WCIOq+w6eJmthWKqxh13vWztzoJVOww77DvoyggjwhDXIVyMMnIRRhzGoNAJgulOIOnr8/4RaW0JDOGS+JDvp+qU5Fy6z3mK4uvpPufEMcYYAQBgCddA7wAAAH1BuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAVhmwcD311FO6/PLLlZ+fr5qaGm3btm2gdgUAYJEBCdd///d/a/78+XrkkUf0xhtvaOLEiaqrq1NbW9tA7A4AwCLOQDxkt6amRtdff73+9V//VZKUyWQ0cuRI3XvvvXrooYf6e3cAABbx9PcbJhIJNTc3a+HChdl5LpdLtbW1ampq6nWbeDyueDye/TmTyejYsWMqLy+X4zgXfZ8BABeWMUYdHR2qrKyUy9W3D//6PVwffvih0um0gsFgzvxgMKi9e/f2us3ixYv12GOP9cfuAQD60cGDBzVixIg+bdPv4ToXCxcu1Pz587M/R6NRVVVV6Sv6pjzKG8A9AwCci5SSek0vqaSkpM/b9nu4hg4dKrfbrdbW1pz5ra2tCoVCvW7j8/nk8/lOme9RnjwO4QIA63x8dcW5fN3T71cVer1eTZo0SRs2bMjOy2Qy2rBhg8LhcH/vDgDAMgPyUeH8+fM1a9YsTZ48WTfccIP++Z//WcePH9d3v/vdgdgdAIBFBiRcd9xxh44cOaJFixYpEonouuuu07p16065YAMAgM8akPu4zlcsFlMgENA3dAvfcQGAhVImqU16QdFoVH6/v0/b8qxCAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWKXP4Xr11Vd18803q7KyUo7j6Pnnn89ZbozRokWLNHz4cBUUFKi2tlbvvPNOzjrHjh3TzJkz5ff7VVpaqtmzZ6uzs/O8DgQAMDj0OVzHjx/XxIkT9dRTT/W6fOnSpXryySf17LPPauvWrSoqKlJdXZ26u7uz68ycOVO7d+/W+vXrtWbNGr366qu6++67z/0oAACDhmOMMee8seNo9erVuvXWWyX1nG1VVlbqgQce0Pe//31JUjQaVTAY1PLly/Xtb39bb7/9tqqrq7V9+3ZNnjxZkrRu3Tp985vf1Pvvv6/Kyso/+b6xWEyBQEDf0C3yOHnnuvsAgAGSMklt0guKRqPy+/192vaCfsd14MABRSIR1dbWZucFAgHV1NSoqalJktTU1KTS0tJstCSptrZWLpdLW7du7fV14/G4YrFYzgQAGJwuaLgikYgkKRgM5swPBoPZZZFIRBUVFTnLPR6PysrKsut81uLFixUIBLLTyJEjL+RuAwAsYsVVhQsXLlQ0Gs1OBw8eHOhdAgAMkAsarlAoJElqbW3Nmd/a2ppdFgqF1NbWlrM8lUrp2LFj2XU+y+fzye/350wAgMHpgoZr9OjRCoVC2rBhQ3ZeLBbT1q1bFQ6HJUnhcFjt7e1qbm7OrrNx40ZlMhnV1NRcyN0BAFyCPH3doLOzU/v378/+fODAAe3YsUNlZWWqqqrSvHnz9I//+I+66qqrNHr0aP3gBz9QZWVl9srDa665RjfddJO+973v6dlnn1UymdTcuXP17W9/+6yuKAQADG59Dtfrr7+uP//zP8/+PH/+fEnSrFmztHz5cv3d3/2djh8/rrvvvlvt7e36yle+onXr1ik/Pz+7zc9+9jPNnTtXU6dOlcvl0owZM/Tkk09egMMBAFzqzus+roHCfVwAYLfPzX1cAABcbIQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYxTPQOwDg0mW8HjmjKmUcR50jvJLLkSR5jqdV8GFS+sMHUjo9wHsJ2xAuAOfOkVRYoLTXkXE72dnGLaWrhqprzDAZn0eSo4z7k826XVKH26hkT6Hcew/KlZQ8XRkpnpBShAxnRrgAnLvQMKXGXKbOKp9S+T3fPCRKpVSRUcIv+Y45yjsueTpzN0uWSCcqpdiVpfLUlqrofUdDdxyX84cPpNaj/X8csArhAtB3jqTQUGWuGK6Oy/OV9jqS0xOtrgoj8/G35/Eyo6RfKjzkyElLXSEjSTlnX6lCqXOUUbw8X77qkcr7aLiUlgpbk8r78IRMyyE5ybQc0+9Hic8pwgWg74YPk0YOV+wLPR8TSlLaJ50InVqXjEfqHGmUf9RRqqD3l0v7pLTPpe7yfLkSkv9dR7GgJFMm6TKV/nKnPEePX7zjgVUIF4C+cRzpsqDipR6l887ywmRHSlamVDykS5KU6vaoO5rf66rGI50YbuT7yJE3ZlTQlpSrYpjkL81d8fCHUnf8PA4EtiJcAM6OIyk0TAoNVbrArWSJW+bjj/yc/IycQiO39/Sf53nyUyoo7ZYkmUzPR4vJE3mSpEzSJWN6Pk500j0fH3pjkitplH8sKQX8UuAzL1haIu15V4onL8LB4vOMcAE4O6Fh0qjhMo7UfnVh9nssSXKNOy7PiG75zvKlHJdRSfCTKza6PipQ4kSe3Pt98n10li/i80pjRkv7W6QT3Wd9GLAf4QJwZo4jBculkUEl/B51l3uy0TJu6USlUWGhkfc0m19W0K6rS9rUnizQmx+N7HWdgiFd8pXEdSIunSjwqvBwz/dmqXyXYqNzP1J0JYyKDn38EWFhvhx/EeEaZAgXgNMrKeo5q3E7kuMo7XWUKPnUJYGOlCzuuQCjN0N9nQoVxFRZEFWBJ6FDXQEdjRcr9anTtXTSpXSy5zXTPikRkJIlRvkfOvIdU+77fSw+pOcNPV0ZlRzNl6vNkTJcdjhY8MgnAL3zF0tXVUkeV89Z12l48lPy+FK9Lvvy0Hc1tqRVkjQkr0u1wX0qzss9O4p3+BQ9GFD0YECJzp7zNuPquay+q0JKFX38Pl2ZnpuUP15uXFKyyKX4mJA0InS+RwuLcMYF4FQFvp5o5X3yT0T0inyl8z/5f914mZSuSMlfGZM7L5OzeUV+h64ve0+FnlMvnPjasP1Kf+qM653CCu0pGp79ueNwiVJxz8fv0XMjszspFbc4klH2ghBJ0smTrNDQnkdHfdB2HgcNWxAuAKdyuXKilSx0K13gUsbtKFUk5ZXF5Q4YFYw6no2W15XSZYXtkqSyvBMqzevq9aVLPLmXsBd6E/L4PnnMU2BkTLEP/Ep29by/8Ugpj9Q+5uQan3wk6I5Lha3qeQaiN+/8jhnWIFwAThVPSEejUnnPNejxIR6lfY66gkapIqlsbIc8rtzvlIo8CX2p/IAko9N/sHgq5zOPxHC5MyoJdSjZ3fPPU6LDp3hn75d+pH1S5wi3Cj7olqvtWB/eFTYjXABOde2Vp5zBOGnJHXeUDGROs1GPbxUfUcidOOu3esPXqcuLjurVtquUkaNoskDypuX29pyF+YoTKjafpDB2qETphFuZlEvedimv0yXz+wPS8d7P8HDpIVwATuVxK1mSp2Rxz3dRqQKXZCSPN6WCsrg+e0o1ovAjfaHwI03Oj6rcnVSB6+yf8O5zpVToTuqm4XskSW/HQop0++Vx0vJ/fCHH/s5h6k73hLR0ZFQnjhXoRGuRilukkvficnf1fnEILk2EC8Cp0hmlChx1VXzyEZ2TkfK8SXnLumSMZD51FlTpi+nakjZNyo+d91tf44/o8qKjcjkZ+VxppY2j97tKFesoVNexnocdpuNuFbQ5csfT8hxPffprLwwChAvAqX63VwUfBpV/NJgzO5rw6MPC8uzPjun5lSWvOGV6+9qIOsa45JbRLcVtGu459+cIFrh7rkaMZ9zafvRytScKlVeYVF5BUt3RfMUjxXJSUjrfpeRHbfLGz/6jSdiPcAE41cjhkr8o+4lgvNSjZJFbGY+TfaqFJCkjeaOS5Oij1FC9kh6ngiFdeit/pL4e+EAV+R1q6y7ReyfKNGnIQbmcU78fe6tzmF7vCJ4yX5I6u/L1+w8qJUmeLskbdZSJ+pRnHBl3z71dXk+xlHdUSvJx4WBBuACcyl8keTxSd0LyeZX2uZQsccvJSAWtvf3qEkepo17terdKbm9agcti2hUZLo8rrc7jBUrsKdH/G3mtikKdPU/Z+Lh9xXlxlbuPa9/RSkUjJTn3aDlJR0UtjryJnu/ZHCNlUsp5tFSy2K2Pbhgmf2ur3Ec/89sqcckiXABOtWt/z39djjRyuApbpcLe1nO5pGFlipd5lChxyx33SPIo9XaZUuq5WThVJOXFpNSHJYqqRPFyKZPXc1m9+4TU0ukor6PnnucTlxm5u3u+T/N+5Mg59TqQHMZRz+8DGzta2vkHKcbv7BoMCBeA08sY6b1Dp1+e55GGDpHvaFLuE2klAh/fNPxxbZx0T7Q+Lf9DSXKU9hoVtyTUFfSqMJKQuzsj/x+krgqfjNuRZGQc58zlOsntlr5Q1fOk+A7idakjXADOXTIlvb5bkuQuyldZ8ipJPQ/G7RjV+y858b/bLc8Hx6R3D0pGKuhplE7eh5x9qpTjKH3dFxQbV6ZM3unr5U4YOcZIvryeM6839kjpM99rBrsRLgDnJ9MTCac7If2x5+zM43WpsPXUp7pLkvtYSk5Ht5TqPS6fvn7D87sDKmmPqaPmMmUKT316hjtuVNLSLVfy4+q5+vLMDtiKcAG4MJIp6dARSZJbp/lOrK8SSeW9E1HgaEzmmit65jmO5OmJopM2cic/dbFI6uxvfIa9+vRrTRYvXqzrr79eJSUlqqio0K233qp9+/blrNPd3a2GhgaVl5eruLhYM2bMUGtra846LS0tqq+vV2FhoSoqKrRgwQKlUlzKCqB37mMn5Pntrp5p2155jh6XpzuTG62uuLT3AB8TDgJ9CldjY6MaGhq0ZcsWrV+/XslkUtOmTdPx4598GXr//ffrxRdf1KpVq9TY2KhDhw7ptttuyy5Pp9Oqr69XIpHQ5s2b9dxzz2n58uVatGjRhTsqAJeuRLLnIozPTu+28LzCQcIxxpzzw1KOHDmiiooKNTY26mtf+5qi0aiGDRumFStW6Pbbb5ck7d27V9dcc42ampo0ZcoUrV27Vt/61rd06NAhBYM9Nx0+++yzevDBB3XkyBF5vaf7BeCfiMViCgQC+oZukcfhVxkAgG1SJqlNekHRaFR+v79P257Xb0CORqOSpLKyMklSc3Ozksmkamtrs+uMHTtWVVVVampqkiQ1NTVp/Pjx2WhJUl1dnWKxmHbv3t3r+8TjccVisZwJADA4nXO4MpmM5s2bpy9/+csaN26cJCkSicjr9aq0tDRn3WAwqEgkkl3n09E6ufzkst4sXrxYgUAgO40cOfJcdxsAYLlzDldDQ4N27dqllStXXsj96dXChQsVjUaz08GDBy/6ewIAPp/O6XL4uXPnas2aNXr11Vc1YsSI7PxQKKREIqH29vacs67W1laFQqHsOtu2bct5vZNXHZ5c57N8Pp98vt5vZgQADC59OuMyxmju3LlavXq1Nm7cqNGjR+csnzRpkvLy8rRhw4bsvH379qmlpUXhcFiSFA6HtXPnTrW1tWXXWb9+vfx+v6qrq8/nWAAAg0CfzrgaGhq0YsUKvfDCCyopKcl+JxUIBFRQUKBAIKDZs2dr/vz5Kisrk9/v17333qtwOKwpU6ZIkqZNm6bq6mrdddddWrp0qSKRiB5++GE1NDRwVgUA+JP6dDm84/T+OJVly5bpr//6ryX13ID8wAMP6Oc//7ni8bjq6ur09NNP53wM+N5772nOnDnatGmTioqKNGvWLC1ZskQez9l1lMvhAcBu53M5/HndxzVQCBcA2G3A7uMCAKC/ES4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYpU/heuaZZzRhwgT5/X75/X6Fw2GtXbs2u7y7u1sNDQ0qLy9XcXGxZsyYodbW1pzXaGlpUX19vQoLC1VRUaEFCxYolUpdmKMBAFzy+hSuESNGaMmSJWpubtbrr7+uG2+8Ubfccot2794tSbr//vv14osvatWqVWpsbNShQ4d02223ZbdPp9Oqr69XIpHQ5s2b9dxzz2n58uVatGjRhT0qAMAlyzHGmPN5gbKyMv3oRz/S7bffrmHDhmnFihW6/fbbJUl79+7VNddco6amJk2ZMkVr167Vt771LR06dEjBYFCS9Oyzz+rBBx/UkSNH5PV6z+o9Y7GYAoGAvqFb5HHyzmf3AQADIGWS2qQXFI1G5ff7+7TtOX/HlU6ntXLlSh0/flzhcFjNzc1KJpOqra3NrjN27FhVVVWpqalJktTU1KTx48dnoyVJdXV1isVi2bO23sTjccVisZwJADA49TlcO3fuVHFxsXw+n+655x6tXr1a1dXVikQi8nq9Ki0tzVk/GAwqEolIkiKRSE60Ti4/uex0Fi9erEAgkJ1GjhzZ190GAFwi+hyuMWPGaMeOHdq6davmzJmjWbNmac+ePRdj37IWLlyoaDSanQ4ePHhR3w8A8Pnl6esGXq9XV155pSRp0qRJ2r59u37yk5/ojjvuUCKRUHt7e85ZV2trq0KhkCQpFApp27ZtOa938qrDk+v0xufzyefz9XVXAQCXoPO+jyuTySgej2vSpEnKy8vThg0bssv27dunlpYWhcNhSVI4HNbOnTvV1taWXWf9+vXy+/2qrq4+310BAAwCfTrjWrhwoaZPn66qqip1dHRoxYoV2rRpk379618rEAho9uzZmj9/vsrKyuT3+3XvvfcqHA5rypQpkqRp06apurpad911l5YuXapIJKKHH35YDQ0NnFEBAM5Kn8LV1tam73znOzp8+LACgYAmTJigX//61/qLv/gLSdITTzwhl8ulGTNmKB6Pq66uTk8//XR2e7fbrTVr1mjOnDkKh8MqKirSrFmz9Pjjj1/YowIAXLLO+z6ugcB9XABgtwG5jwsAgIFAuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKoQLAGAVwgUAsArhAgBYhXABAKxCuAAAViFcAACrEC4AgFUIFwDAKucVriVLlshxHM2bNy87r7u7Ww0NDSovL1dxcbFmzJih1tbWnO1aWlpUX1+vwsJCVVRUaMGCBUqlUuezKwCAQeKcw7V9+3b927/9myZMmJAz//7779eLL76oVatWqbGxUYcOHdJtt92WXZ5Op1VfX69EIqHNmzfrueee0/Lly7Vo0aJzPwoAwKBxTuHq7OzUzJkz9e///u8aMmRIdn40GtVPf/pT/fjHP9aNN96oSZMmadmyZdq8ebO2bNkiSXr55Ze1Z88e/dd//Zeuu+46TZ8+XT/84Q/11FNPKZFIXJijAgBcss4pXA0NDaqvr1dtbW3O/ObmZiWTyZz5Y8eOVVVVlZqamiRJTU1NGj9+vILBYHaduro6xWIx7d69u9f3i8fjisViORMAYHDy9HWDlStX6o033tD27dtPWRaJROT1elVaWpozPxgMKhKJZNf5dLROLj+5rDeLFy/WY4891tddBQBcgvp0xnXw4EHdd999+tnPfqb8/PyLtU+nWLhwoaLRaHY6ePBgv703AODzpU/ham5uVltbm774xS/K4/HI4/GosbFRTz75pDwej4LBoBKJhNrb23O2a21tVSgUkiSFQqFTrjI8+fPJdT7L5/PJ7/fnTACAwalP4Zo6dap27typHTt2ZKfJkydr5syZ2T/n5eVpw4YN2W327dunlpYWhcNhSVI4HNbOnTvV1taWXWf9+vXy+/2qrq6+QIcFALhU9ek7rpKSEo0bNy5nXlFRkcrLy7PzZ8+erfnz56usrEx+v1/33nuvwuGwpkyZIkmaNm2aqqurddddd2np0qWKRCJ6+OGH1dDQIJ/Pd4EOCwBwqerzxRl/yhNPPCGXy6UZM2YoHo+rrq5OTz/9dHa52+3WmjVrNGfOHIXDYRUVFWnWrFl6/PHHL/SuAAAuQY4xxgz0TvRVLBZTIBDQN3SLPE7eQO8OAKCPUiapTXpB0Wi0z9ct8KxCAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWIVwAQCsQrgAAFYhXAAAqxAuAIBVCBcAwCqECwBgFcIFALAK4QIAWKVP4Xr00UflOE7ONHbs2Ozy7u5uNTQ0qLy8XMXFxZoxY4ZaW1tzXqOlpUX19fUqLCxURUWFFixYoFQqdWGOBgBwyfP0dYNrr71Wr7zyyicv4PnkJe6//3796le/0qpVqxQIBDR37lzddttt+u1vfytJSqfTqq+vVygU0ubNm3X48GF95zvfUV5env7pn/7pAhwOAOBS1+dweTwehUKhU+ZHo1H99Kc/1YoVK3TjjTdKkpYtW6ZrrrlGW7Zs0ZQpU/Tyyy9rz549euWVVxQMBnXdddfphz/8oR588EE9+uij8nq9539EAIBLWp+/43rnnXdUWVmpK664QjNnzlRLS4skqbm5WclkUrW1tdl1x44dq6qqKjU1NUmSmpqaNH78eAWDwew6dXV1isVi2r1792nfMx6PKxaL5UwAgMGpT+GqqanR8uXLtW7dOj3zzDM6cOCAvvrVr6qjo0ORSERer1elpaU52wSDQUUiEUlSJBLJidbJ5SeXnc7ixYsVCASy08iRI/uy2wCAS0ifPiqcPn169s8TJkxQTU2NRo0apV/84hcqKCi44Dt30sKFCzV//vzsz7FYjHgBwCB1XpfDl5aW6uqrr9b+/fsVCoWUSCTU3t6es05ra2v2O7FQKHTKVYYnf+7te7OTfD6f/H5/zgQAGJzOK1ydnZ169913NXz4cE2aNEl5eXnasGFDdvm+ffvU0tKicDgsSQqHw9q5c6fa2tqy66xfv15+v1/V1dXnsysAgEGiTx8Vfv/739fNN9+sUaNG6dChQ3rkkUfkdrt15513KhAIaPbs2Zo/f77Kysrk9/t17733KhwOa8qUKZKkadOmqbq6WnfddZeWLl2qSCSihx9+WA0NDfL5fBflAAEAl5Y+hev999/XnXfeqaNHj2rYsGH6yle+oi1btmjYsGGSpCeeeEIul0szZsxQPB5XXV2dnn766ez2brdba9as0Zw5cxQOh1VUVKRZs2bp8ccfv7BHBQC4ZDnGGDPQO9FXsVhMgUBA39At8jh5A707AIA+SpmkNukFRaPRPl+30OcbkD8PTrY2paRkXXYBACklJX3y73lfWBmuo0ePSpJe00sDvCcAgPPR0dGhQCDQp22sDFdZWZmkngf29vWAB4uT97odPHiQ2wd6wficGeNzZozPmZ3N+Bhj1NHRocrKyj6/vpXhcrl6ruIPBAL8pfkTuO/tzBifM2N8zozxObM/NT7neuLB7+MCAFiFcAEArGJluHw+nx555BFuWj4DxujMGJ8zY3zOjPE5s4s9PlbexwUAGLysPOMCAAxehAsAYBXCBQCwCuECAFjFynA99dRTuvzyy5Wfn6+amhpt27ZtoHepX7z66qu6+eabVVlZKcdx9Pzzz+csN8Zo0aJFGj58uAoKClRbW6t33nknZ51jx45p5syZ8vv9Ki0t1ezZs9XZ2dmPR3HxLF68WNdff71KSkpUUVGhW2+9Vfv27ctZp7u7Ww0NDSovL1dxcbFmzJhxyi83bWlpUX19vQoLC1VRUaEFCxYolUr156FcFM8884wmTJiQvSk0HA5r7dq12eWDeWx6s2TJEjmOo3nz5mXnDeYxevTRR+U4Ts40duzY7PJ+HRtjmZUrVxqv12v+8z//0+zevdt873vfM6Wlpaa1tXWgd+2ie+mll8w//MM/mF/+8pdGklm9enXO8iVLlphAIGCef/5587vf/c785V/+pRk9erTp6urKrnPTTTeZiRMnmi1btpj/+7//M1deeaW58847+/lILo66ujqzbNkys2vXLrNjxw7zzW9+01RVVZnOzs7sOvfcc48ZOXKk2bBhg3n99dfNlClTzJe+9KXs8lQqZcaNG2dqa2vNm2++aV566SUzdOhQs3DhwoE4pAvqf//3f82vfvUr8/vf/97s27fP/P3f/73Jy8szu3btMsYM7rH5rG3btpnLL7/cTJgwwdx3333Z+YN5jB555BFz7bXXmsOHD2enI0eOZJf359hYF64bbrjBNDQ0ZH9Op9OmsrLSLF68eAD3qv99NlyZTMaEQiHzox/9KDuvvb3d+Hw+8/Of/9wYY8yePXuMJLN9+/bsOmvXrjWO45gPPvig3/a9v7S1tRlJprGx0RjTMx55eXlm1apV2XXefvttI8k0NTUZY3r+58DlcplIJJJd55lnnjF+v9/E4/H+PYB+MGTIEPMf//EfjM2ndHR0mKuuusqsX7/efP3rX8+Ga7CP0SOPPGImTpzY67L+HhurPipMJBJqbm5WbW1tdp7L5VJtba2ampoGcM8G3oEDBxSJRHLGJhAIqKamJjs2TU1NKi0t1eTJk7Pr1NbWyuVyaevWrf2+zxdbNBqV9MlDmZubm5VMJnPGaOzYsaqqqsoZo/HjxysYDGbXqaurUywW0+7du/tx7y+udDqtlStX6vjx4wqHw4zNpzQ0NKi+vj5nLCT+/kjSO++8o8rKSl1xxRWaOXOmWlpaJPX/2Fj1kN0PP/xQ6XQ658AlKRgMau/evQO0V58PkUhEknodm5PLIpGIKioqcpZ7PB6VlZVl17lUZDIZzZs3T1/+8pc1btw4ST3H7/V6VVpamrPuZ8eotzE8ucx2O3fuVDgcVnd3t4qLi7V69WpVV1drx44dg35sJGnlypV64403tH379lOWDfa/PzU1NVq+fLnGjBmjw4cP67HHHtNXv/pV7dq1q9/HxqpwAWeroaFBu3bt0muvvTbQu/K5MmbMGO3YsUPRaFT/8z//o1mzZqmxsXGgd+tz4eDBg7rvvvu0fv165efnD/TufO5Mnz49++cJEyaopqZGo0aN0i9+8QsVFBT0675Y9VHh0KFD5Xa7T7lSpbW1VaFQaID26vPh5PGfaWxCoZDa2tpylqdSKR07duySGr+5c+dqzZo1+s1vfqMRI0Zk54dCISUSCbW3t+es/9kx6m0MTy6zndfr1ZVXXqlJkyZp8eLFmjhxon7yk58wNur5uKutrU1f/OIX5fF45PF41NjYqCeffFIej0fBYHDQj9GnlZaW6uqrr9b+/fv7/e+PVeHyer2aNGmSNmzYkJ2XyWS0YcMGhcPhAdyzgTd69GiFQqGcsYnFYtq6dWt2bMLhsNrb29Xc3JxdZ+PGjcpkMqqpqen3fb7QjDGaO3euVq9erY0bN2r06NE5yydNmqS8vLycMdq3b59aWlpyxmjnzp05gV+/fr38fr+qq6v750D6USaTUTweZ2wkTZ06VTt37tSOHTuy0+TJkzVz5szsnwf7GH1aZ2en3n33XQ0fPrz///70+dKSAbZy5Urj8/nM8uXLzZ49e8zdd99tSktLc65UuVR1dHSYN99807z55ptGkvnxj39s3nzzTfPee+8ZY3ouhy8tLTUvvPCCeeutt8wtt9zS6+Xwf/Znf2a2bt1qXnvtNXPVVVddMpfDz5kzxwQCAbNp06acS3ZPnDiRXeeee+4xVVVVZuPGjeb111834XDYhMPh7PKTl+xOmzbN7Nixw6xbt84MGzbskric+aGHHjKNjY3mwIED5q233jIPPfSQcRzHvPzyy8aYwT02p/PpqwqNGdxj9MADD5hNmzaZAwcOmN/+9remtrbWDB061LS1tRlj+ndsrAuXMcb8y7/8i6mqqjJer9fccMMNZsuWLQO9S/3iN7/5jZF0yjRr1ixjTM8l8T/4wQ9MMBg0Pp/PTJ061ezbty/nNY4ePWruvPNOU1xcbPx+v/nud79rOjo6BuBoLrzexkaSWbZsWXadrq4u87d/+7dmyJAhprCw0PzVX/2VOXz4cM7r/PGPfzTTp083BQUFZujQoeaBBx4wyWSyn4/mwvubv/kbM2rUKOP1es2wYcPM1KlTs9EyZnCPzel8NlyDeYzuuOMOM3z4cOP1es1ll11m7rjjDrN///7s8v4cG36tCQDAKlZ9xwUAAOECAFiFcAEArEK4AABWIVwAAKsQLgCAVQgXAMAqhAsAYBXCBQCwCuECAFiFcAEArEK4AABW+f874OIp57BYKwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(nnunet_train_dir,\"labelsTr\")))\n",
    "# visualize one of the images\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from numpy import spacing\n",
    "img_path = os.path.join(nnunet_train_dir, \"labelsTr\", os.listdir(os.path.join(nnunet_train_dir, \"labelsTr\"))[0])\n",
    "img = nib.load(img_path)\n",
    "img_data = img.get_fdata()\n",
    "spacing = img.header.get_zooms()\n",
    "print(f\"Image shape: {img_data.shape}\")\n",
    "gt1 = img_data == 1\n",
    "plt.imshow(gt1.mean(axis=0),)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the variables for dataset location (see https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/set_environment_variables.md)\n",
    "import os\n",
    "os.environ[\"nnUNet_raw\"] = os.path.join(config[\"DATA_DIR\"], \"nnunet_raw\")\n",
    "os.environ[\"nnUNet_preprocessed\"] = os.path.join(config[\"DATA_DIR\"], \"nnUNet_preprocessed\") \n",
    "os.environ[\"nnUNet_results\"] = os.path.join(config[\"DATA_DIR\"], \"nnUNet_results\")\n",
    "os.environ[\"NNINT_CKPT_DIR\"] = config[\"NNINT_CKPT_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export nnUNet_raw=/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnunet_raw\n",
      "export nnUNet_preprocessed=/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_preprocessed\n",
      "export nnUNet_results=/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_results\n",
      "export NNINT_CKPT_DIR=/nfs/norasys/notebooks/camaret/model_checkpoints/nnint\n"
     ]
    }
   ],
   "source": [
    "# easy paste when using a terminal\n",
    "for var_name in [\"nnUNet_raw\", \"nnUNet_preprocessed\", \"nnUNet_results\",\"NNINT_CKPT_DIR\"]:\n",
    "    print(\"export \" + var_name + \"=\" + os.environ[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2039321317.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m--time=2-0 --nodelist=loki --gpus-per-node=2  --cpus-per-task=16 --mem=64G\u001b[39m\n                                                                            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "# Ressource request on nora\n",
    "\n",
    "--time=2-0 --nodelist=loki --gpus-per-node=1  --cpus-per-task=16 --mem=64G\n",
    "\n",
    "source /software/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate segfm3d_2\n",
    "cd /nfs/norasys/notebooks/camaret/segfm3d_nora_team\n",
    "/software/inetaccess/inetaccess camaret\n",
    "\n",
    "export TORCH_COMPILE_DISABLE=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using nninteractive plans :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnUNetv2_extract_fingerprint -d 7 --verify_dataset_integrity\n",
    "\n",
    "\n",
    "# a) using ResEnc plans : \n",
    "nnUNetv2_plan_experiment -d 7 -pl nnUNetPlannerResEncL\n",
    "nnUNetv2_preprocess -d 7 -c 3d_fullres\n",
    "\n",
    "\n",
    "# b) using plans from nnInteractive_v1.0 :\n",
    "# cp nnInteractive_v1.0/plans.json $nnUNet_preprocessed/DatasetXXX_XXX/nnUNetResEncUNetLPlans_noResampling.json\n",
    "# in nnUNetResEncUNetLPlans_noResampling.json :\n",
    "# change the \"dataset_name\" field to the current one\n",
    "# change the \"resampling...\" fields to another method since we cannot access \"no_resampling_hack\" (e.g. \"resample_data_or_seg_to_shape\")\n",
    "# add a method 3d_fullres_ps192_bs1 that sets batch size = 1 since we are gpu poor \n",
    "\n",
    "# preprocess the dataset\n",
    "nnUNetv2_preprocess -d 6 -np 12 -plans_name nnUNetResEncUNetLPlans_noResampling -c 3d_fullres_ps192_bs1\n",
    "\n",
    "\n",
    "# define a custom trainer in  nnUNet/nnunetv2/training/nnUNetTrainer/CustomTrainer.py\n",
    "# train using the custom trainer with our preprocessing steps\n",
    "nnUNetv2_train 6 3d_fullres_ps192 0 -p nnUNetResEncUNetLPlans_noResampling -tr CustomTrainer -num_gpus 1 -pretrained_weights $NNINT_CKPT_DIR/nnInteractive_v1.0/fold_0/checkpoint_final.pth\n",
    "# additional args : \n",
    "-num_gpus 1 -pretrained_weights /nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/checkpoints/nnInteractive_v1.0/fold_0/checkpoint_final.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp nnInteractive_v1.0/inference_session_class.json to $nnUNet_results/DatasetXXX_XXX/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs1\n",
    "\n",
    "# weights are ready to be picked by the nnInteractive.inference.inference_session class\n",
    "import torch\n",
    "from nnInteractive.inference.inference_session import nnInteractiveInferenceSession\n",
    "session = nnInteractiveInferenceSession(\n",
    "    device=torch.device(\"cpu\"),  # Set inference device\n",
    "    use_torch_compile=False,  # Experimental: Not tested yet\n",
    "    verbose=False,\n",
    "    torch_n_threads=1,  # Use available CPU cores\n",
    "    do_autozoom=True,  # Enables AutoZoom for better patching\n",
    "    use_pinned_memory=True,  # Optimizes GPU memory transfers\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network architecture with 8 input channels\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model_training_output_dir = os.path.join(os.environ[\"nnUNet_results\"], \"Dataset002_CT_Abdomen1K/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs1\")\n",
    "model_training_output_dir = os.path.join(os.environ[\"nnUNet_results\"], \"Dataset006_AMOS/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192\")\n",
    "\n",
    "session.initialize_from_trained_model_folder(model_training_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the trained model on the segfm3d task : \n",
    "python scripts/eval.py -ca 0 -m nnint_custom --checkpoint_path /nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_results/Dataset006_AMOS/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192\n",
    "python scripts/eval.py -ca 0 -m nnint_custom --checkpoint_path $NNINT_CKPT_DIR/nnInteractive_ours\n",
    "\n",
    "python scripts/eval.py -ca 0 -m nnint_custom --checkpoint_path $nnUNet_results/Dataset006_AMOS/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network architecture with 8 input channels\n",
      "Model Info:\n",
      "model_type: ResidualEncoderUNet\n",
      "model_module: dynamic_network_architectures.architectures.unet\n",
      "num_parameters: 102355818\n",
      "input_channels: 1\n",
      "output_classes: 2\n",
      "configuration_name: 3d_fullres_ps192_bs1\n",
      "network_arch_class_name: dynamic_network_architectures.architectures.unet.ResidualEncoderUNet\n",
      "network_arch_init_kwargs: {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}\n",
      "network_arch_init_kwargs_req_import: ['conv_op', 'norm_op', 'dropout_op', 'nonlin']\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Also possible to avoid the nnInteractive class alltogether\n",
    "\n",
    "from nnunetv2.utilities.label_handling.label_handling import determine_num_input_channels\n",
    "from nnunetv2.utilities.find_class_by_name import recursive_find_python_class\n",
    "\n",
    "from nnunetv2.utilities.plans_handling.plans_handler import PlansManager, ConfigurationManager\n",
    "from batchgenerators.utilities.file_and_folder_operations import load_json, join, subdirs\n",
    "from nnInteractive.trainer.nnInteractiveTrainer import nnInteractiveTrainer_stub\n",
    "\n",
    "import nnInteractive\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_json = load_json(join(model_training_output_dir, 'dataset.json'))\n",
    "plans = load_json(os.path.join(model_training_output_dir, 'plans.json'))\n",
    "plans_manager = PlansManager(plans)\n",
    "checkpoint = torch.load(os.path.join(model_training_output_dir,\"fold_0/checkpoint_final.pth\"), map_location=device, weights_only=False)\n",
    "\n",
    "configuration_name = checkpoint['init_args']['configuration']\n",
    "\n",
    "parameters = checkpoint['network_weights']\n",
    "\n",
    "configuration_manager = plans_manager.get_configuration(configuration_name)\n",
    "\n",
    "trainer_name = checkpoint['trainer_name']\n",
    "\n",
    "num_input_channels = determine_num_input_channels(plans_manager, configuration_manager, dataset_json)\n",
    "\n",
    "\n",
    "trainer_class = recursive_find_python_class(join(nnInteractive.__path__[0], \"trainer\"),\n",
    "                                            trainer_name, 'nnInteractive.trainer')\n",
    "if trainer_class is None:\n",
    "    print(f'Unable to locate trainer class {trainer_name} in nnInteractive.trainer. '\n",
    "                        f'Please place it there (in any .py file)!')\n",
    "    print('Attempting to use default nnInteractiveTrainer_stub. If you encounter errors, this is where you need to look!')\n",
    "    trainer_class = nnInteractiveTrainer_stub\n",
    "\n",
    "network = trainer_class.build_network_architecture(\n",
    "    configuration_manager.network_arch_class_name,\n",
    "    configuration_manager.network_arch_init_kwargs,\n",
    "    configuration_manager.network_arch_init_kwargs_req_import,\n",
    "    num_input_channels,\n",
    "    plans_manager.get_label_manager(dataset_json).num_segmentation_heads,\n",
    "    enable_deep_supervision=False\n",
    ").to(device)\n",
    "network.load_state_dict(parameters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_info = {\n",
    "    \"model_type\": type(network).__name__,\n",
    "    \"model_module\": type(network).__module__,\n",
    "    \"num_parameters\": sum(p.numel() for p in network.parameters()),\n",
    "    \"input_channels\": num_input_channels,\n",
    "    \"output_classes\": plans_manager.get_label_manager(dataset_json).num_segmentation_heads,\n",
    "    \"configuration_name\": configuration_name,\n",
    "    \"network_arch_class_name\": configuration_manager.network_arch_class_name,\n",
    "    \"network_arch_init_kwargs\": configuration_manager.network_arch_init_kwargs,\n",
    "    \"network_arch_init_kwargs_req_import\": configuration_manager.network_arch_init_kwargs_req_import\n",
    "}\n",
    "\n",
    "print(\"Model Info:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATA_DIR': '/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data',\n",
       " 'RESULTS_DIR': '/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/results',\n",
       " 'SAM_CKPT_PATH': '/nfs/norasys/notebooks/camaret/SAM-Med3D/ckpt/sam_med3d_turbo_bbox_cvpr.pth',\n",
       " 'SAM_REPO_DIR': '/nfs/norasys/notebooks/camaret/SAM-Med3D',\n",
       " 'ONNX_MODEL_PATH': '/nfs/norasys/notebooks/camaret/model_inference/models/sammed3d.onnx',\n",
       " 'NNINT_CKPT_DIR': '/nfs/norasys/notebooks/camaret/model_checkpoints/nnint'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segfm3d_2",
   "language": "python",
   "name": "segfm3d_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
