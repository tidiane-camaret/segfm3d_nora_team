{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model using the nnUnet library \n",
    "see https://github.com/MIC-DKFZ/nnUNet/tree/master\n",
    "\n",
    "1 - Convert a subset the competition dataset to nnunet format\n",
    "2 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnunet_dataset_name = \"Dataset004_10percent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import config\n",
    "import os\n",
    "nnunet_train_dir = os.path.join(config[\"DATA_DIR\"], \"nnunet_raw\", nnunet_dataset_name)\n",
    "os.makedirs(nnunet_train_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"imagesTr\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"imagesTs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"labelsTr\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"labelsTs\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only a subdir\n",
    "\"\"\"\n",
    "subset_name = \"CT/CT_Abdomen1K\" # using a subset for now\n",
    "train_dir = os.path.join(config[\"DATA_DIR\"], \"3D_train_npz_random_10percent_16G\", subset_name)\n",
    "files = os.listdir(train_dir)\n",
    "\"\"\"\n",
    "# or full dataset\n",
    "files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(os.path.join(config[\"DATA_DIR\"], \"3D_train_npz_random_10percent_16G\")) for f in filenames if os.path.splitext(f)[1] == '.npz']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/3D_train_npz_random_10percent_16G/Ultrasound/US_Low-limb-Leg/US_Low-limb-Leg07.npz'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "def process_file(file_info, train_dir, nnunet_train_dir, total_files):\n",
    "    i, file = file_info\n",
    "    subset = \"Tr\" if i < total_files * 0.8 else \"Ts\"\n",
    "    print(f\"file : {os.path.basename(file)}, {i}/{total_files}\")\n",
    "    \n",
    "    data = np.load( file, allow_pickle=True)\n",
    "    imgs = data[\"imgs\"]\n",
    "    \n",
    "    # Create affine matrix\n",
    "    affine = np.eye(4)\n",
    "    affine[0, 0] = data[\"spacing\"][0]\n",
    "    affine[1, 1] = data[\"spacing\"][1]\n",
    "    affine[2, 2] = data[\"spacing\"][2]\n",
    "    \n",
    "    # Save images\n",
    "    nib_img = nib.Nifti1Image(imgs, affine=affine)\n",
    "    nib.save(nib_img, os.path.join(nnunet_train_dir, \"images\"+subset, os.path.basename(file).replace(\".npz\", \"_0000.nii.gz\")))\n",
    "    \n",
    "    # Process and save ground truth\n",
    "    gts = data[\"gts\"]\n",
    "    #gts = (gts == 1).astype(np.int8)\n",
    "    nib_gt = nib.Nifti1Image(gts, affine=affine)\n",
    "    nib.save(nib_gt, os.path.join(nnunet_train_dir, \"labels\"+subset, os.path.basename(file).replace(\".npz\", \".nii.gz\")))\n",
    "    \n",
    "    return file\n",
    "\n",
    "# Main execution\n",
    "# Create list of (index, filename) tuples\n",
    "file_list = [(i, file) for i, file in enumerate(files)]\n",
    "\n",
    "# Create partial function with fixed arguments\n",
    "process_func = partial(process_file, \n",
    "                      train_dir=train_dir, \n",
    "                      nnunet_train_dir=nnunet_train_dir, \n",
    "                      total_files=len(files))\n",
    "\n",
    "# Use 14 cores (leave 2 for system)\n",
    "with Pool(processes=14) as pool:\n",
    "    results = pool.map(process_func, file_list)\n",
    "\n",
    "print(f\"Processed {len(results)} files successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2388"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(nnunet_train_dir,\"imagesTr\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the variables for dataset location (see https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/set_environment_variables.md)\n",
    "\n",
    "os.environ[\"nnUNet_raw\"] = os.path.join(config[\"DATA_DIR\"], \"nnunet_raw\")\n",
    "os.environ[\"nnUNet_preprocessed\"] = os.path.join(config[\"DATA_DIR\"], \"nnUNet_preprocessed\") \n",
    "os.environ[\"nnUNet_results\"] = os.path.join(config[\"DATA_DIR\"], \"nnUNet_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export nnUNet_raw=/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnunet_raw\n",
      "export nnUNet_preprocessed=/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_preprocessed\n",
      "export nnUNet_results=/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "# easy paste when using a terminal\n",
    "for var_name in [\"nnUNet_raw\", \"nnUNet_preprocessed\", \"nnUNet_results\"]:\n",
    "    print(\"export \" + var_name + \"=\" + os.environ[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# Ressource request on nora\n",
    "\n",
    "--time=2-0 --nodelist=loki --gpus-per-node=2  --cpus-per-task=16 --mem=64G\n",
    "\n",
    "source /software/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate segfm3d_2\n",
    "cd /nfs/norasys/notebooks/camaret/segfm3d_nora_team\n",
    "/software/inetaccess/inetaccess camaret\n",
    "\n",
    "export TORCH_COMPILE_DISABLE=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using nninteractive plans :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp nnInteractive_v1.0/plans.json $nnUNet_preprocessed/DatasetXXX_XXX/nnUNetResEncUNetLPlans_noResampling.json\n",
    "\n",
    "# add a 3d_fullres_ps192_bs1 that sets batch size = 1 since we are gpu poor \n",
    "\n",
    "# preprocess the dataset\n",
    "nnUNetv2_preprocess -d 4 -np 12 -plans_name nnUNetResEncUNetLPlans_noResampling -c 3d_fullres_ps192_bs1\n",
    "\n",
    "\n",
    "# define a custom trainer in  nnUNet/nnunetv2/training/nnUNetTrainer/CustomTrainer.py\n",
    "# train using the custom trainer with our preprocessing steps\n",
    "nnUNetv2_train 4 3d_fullres_ps192 0 -p nnUNetResEncUNetLPlans_noResampling -tr CustomTrainer --num_gpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network architecture with 8 input channels\n"
     ]
    }
   ],
   "source": [
    "# cp nnInteractive_v1.0/inference_session_class.json to $nnUNet_results/DatasetXXX_XXX/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs1\n",
    "\n",
    "# weights are ready to be picked by the nnInteractive.inference.inference_session class\n",
    "import torch\n",
    "from nnInteractive.inference.inference_session import nnInteractiveInferenceSession\n",
    "session = nnInteractiveInferenceSession(\n",
    "    device=torch.device(\"cuda:0\"),  # Set inference device\n",
    "    use_torch_compile=False,  # Experimental: Not tested yet\n",
    "    verbose=False,\n",
    "    torch_n_threads=os.cpu_count(),  # Use available CPU cores\n",
    "    do_autozoom=True,  # Enables AutoZoom for better patching\n",
    "    use_pinned_memory=True,  # Optimizes GPU memory transfers\n",
    ")\n",
    "\n",
    "# Load the trained model\n",
    "model_path = os.path.join(os.environ[\"nnUNet_results\"], \"Dataset002_CT_Abdomen1K/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs1\")\n",
    "session.initialize_from_trained_model_folder(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network architecture with 8 input channels\n",
      "Model Info:\n",
      "model_type: ResidualEncoderUNet\n",
      "model_module: dynamic_network_architectures.architectures.unet\n",
      "num_parameters: 102355818\n",
      "input_channels: 1\n",
      "output_classes: 2\n",
      "configuration_name: 3d_fullres_ps192_bs1\n",
      "network_arch_class_name: dynamic_network_architectures.architectures.unet.ResidualEncoderUNet\n",
      "network_arch_init_kwargs: {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}\n",
      "network_arch_init_kwargs_req_import: ['conv_op', 'norm_op', 'dropout_op', 'nonlin']\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Also possible to avoid the nnInteractive class alltogether\n",
    "\n",
    "from nnunetv2.utilities.label_handling.label_handling import determine_num_input_channels\n",
    "from nnunetv2.utilities.find_class_by_name import recursive_find_python_class\n",
    "\n",
    "from nnunetv2.utilities.plans_handling.plans_handler import PlansManager, ConfigurationManager\n",
    "from batchgenerators.utilities.file_and_folder_operations import load_json, join, subdirs\n",
    "from nnInteractive.trainer.nnInteractiveTrainer import nnInteractiveTrainer_stub\n",
    "\n",
    "import nnInteractive\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_training_output_dir = model_path\n",
    "dataset_json = load_json(join(model_training_output_dir, 'dataset.json'))\n",
    "plans = load_json(os.path.join(model_training_output_dir, 'plans.json'))\n",
    "plans_manager = PlansManager(plans)\n",
    "checkpoint = torch.load(os.path.join(model_training_output_dir,\"fold_0/checkpoint_final.pth\"), map_location=device, weights_only=False)\n",
    "\n",
    "configuration_name = checkpoint['init_args']['configuration']\n",
    "\n",
    "parameters = checkpoint['network_weights']\n",
    "\n",
    "configuration_manager = plans_manager.get_configuration(configuration_name)\n",
    "\n",
    "trainer_name = checkpoint['trainer_name']\n",
    "\n",
    "num_input_channels = determine_num_input_channels(plans_manager, configuration_manager, dataset_json)\n",
    "\n",
    "\n",
    "trainer_class = recursive_find_python_class(join(nnInteractive.__path__[0], \"trainer\"),\n",
    "                                            trainer_name, 'nnInteractive.trainer')\n",
    "if trainer_class is None:\n",
    "    print(f'Unable to locate trainer class {trainer_name} in nnInteractive.trainer. '\n",
    "                        f'Please place it there (in any .py file)!')\n",
    "    print('Attempting to use default nnInteractiveTrainer_stub. If you encounter errors, this is where you need to look!')\n",
    "    trainer_class = nnInteractiveTrainer_stub\n",
    "\n",
    "network = trainer_class.build_network_architecture(\n",
    "    configuration_manager.network_arch_class_name,\n",
    "    configuration_manager.network_arch_init_kwargs,\n",
    "    configuration_manager.network_arch_init_kwargs_req_import,\n",
    "    num_input_channels,\n",
    "    plans_manager.get_label_manager(dataset_json).num_segmentation_heads,\n",
    "    enable_deep_supervision=False\n",
    ").to(device)\n",
    "network.load_state_dict(parameters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_info = {\n",
    "    \"model_type\": type(network).__name__,\n",
    "    \"model_module\": type(network).__module__,\n",
    "    \"num_parameters\": sum(p.numel() for p in network.parameters()),\n",
    "    \"input_channels\": num_input_channels,\n",
    "    \"output_classes\": plans_manager.get_label_manager(dataset_json).num_segmentation_heads,\n",
    "    \"configuration_name\": configuration_name,\n",
    "    \"network_arch_class_name\": configuration_manager.network_arch_class_name,\n",
    "    \"network_arch_init_kwargs\": configuration_manager.network_arch_init_kwargs,\n",
    "    \"network_arch_init_kwargs_req_import\": configuration_manager.network_arch_init_kwargs_req_import\n",
    "}\n",
    "\n",
    "print(\"Model Info:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"Model loaded successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segfm3d_2",
   "language": "python",
   "name": "segfm3d_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
