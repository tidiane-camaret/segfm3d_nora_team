{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model using the nnUnet library \n",
    "see https://github.com/MIC-DKFZ/nnUNet/tree/master\n",
    "\n",
    "1 - Convert a subset the competition dataset to nnunet format\n",
    "2 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnunet_dataset_name = \"Dataset005_AMOS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import config\n",
    "import os\n",
    "nnunet_train_dir = os.path.join(config[\"DATA_DIR\"], \"nnunet_raw\", nnunet_dataset_name)\n",
    "os.makedirs(nnunet_train_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"imagesTr\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"imagesTs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"labelsTr\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(nnunet_train_dir, \"labelsTs\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# or full dataset\\nfiles = [os.path.join(dp, f) for dp, dn, filenames in os.walk(os.path.join(config[\"DATA_DIR\"], \"3D_train_npz_random_10percent_16G\")) for f in filenames if os.path.splitext(f)[1] == \\'.npz\\']\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use only a subdir\n",
    "\n",
    "subset_name = \"CT/CT_AMOS\" # using a subset for now\n",
    "train_dir = os.path.join(config[\"DATA_DIR\"], \"3D_train_npz_random_10percent_16G\", subset_name)\n",
    "files = [os.path.join(train_dir,f) for f in os.listdir(train_dir) if os.path.splitext(f)[1] == '.npz']\n",
    "\"\"\"\n",
    "# or full dataset\n",
    "files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(os.path.join(config[\"DATA_DIR\"], \"3D_train_npz_random_10percent_16G\")) for f in filenames if os.path.splitext(f)[1] == '.npz']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Processed 30 files successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "def process_file(file_info, train_dir, nnunet_train_dir, total_files):\n",
    "    i, file = file_info\n",
    "    subset = \"Tr\" if i < total_files * 0.8 else \"Ts\"\n",
    "    #print(f\"file : {os.path.basename(file)}, {i}/{total_files}\")\n",
    "    \n",
    "    data = np.load( file, allow_pickle=True)\n",
    "    imgs = data[\"imgs\"]\n",
    "    \n",
    "    # Create affine matrix\n",
    "    affine = np.eye(4)\n",
    "    affine[0, 0] = data[\"spacing\"][0]\n",
    "    affine[1, 1] = data[\"spacing\"][1]\n",
    "    affine[2, 2] = data[\"spacing\"][2]\n",
    "    \n",
    "    # Save images\n",
    "    nib_img = nib.Nifti1Image(imgs, affine=affine)\n",
    "    nib.save(nib_img, os.path.join(nnunet_train_dir, \"images\"+subset, os.path.basename(file).replace(\".npz\", \"_0000.nii.gz\")))\n",
    "    \n",
    "    # Process and save ground truth\n",
    "    gts = data[\"gts\"]\n",
    "    print(np.unique(gts))\n",
    "    #gts = (gts == 1).astype(np.int8)\n",
    "    nib_gt = nib.Nifti1Image(gts, affine=affine)\n",
    "    nib.save(nib_gt, os.path.join(nnunet_train_dir, \"labels\"+subset, os.path.basename(file).replace(\".npz\", \".nii.gz\")))\n",
    "    \n",
    "    return file\n",
    "\n",
    "# Main execution\n",
    "# Create list of (index, filename) tuples\n",
    "file_list = [(i, file) for i, file in enumerate(files)]\n",
    "\n",
    "# Create partial function with fixed arguments\n",
    "process_func = partial(process_file, \n",
    "                      train_dir=train_dir, \n",
    "                      nnunet_train_dir=nnunet_train_dir, \n",
    "                      total_files=len(files))\n",
    "\n",
    "# Use 14 cores (leave 2 for system)\n",
    "with Pool(processes=14) as pool:\n",
    "    results = pool.map(process_func, file_list)\n",
    "\n",
    "print(f\"Processed {len(results)} files successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(nnunet_train_dir,\"imagesTr\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the variables for dataset location (see https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/set_environment_variables.md)\n",
    "\n",
    "os.environ[\"nnUNet_raw\"] = os.path.join(config[\"DATA_DIR\"], \"nnunet_raw\")\n",
    "os.environ[\"nnUNet_preprocessed\"] = os.path.join(config[\"DATA_DIR\"], \"nnUNet_preprocessed\") \n",
    "os.environ[\"nnUNet_results\"] = os.path.join(config[\"DATA_DIR\"], \"nnUNet_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export nnUNet_raw=/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnunet_raw\n",
      "export nnUNet_preprocessed=/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_preprocessed\n",
      "export nnUNet_results=/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "# easy paste when using a terminal\n",
    "for var_name in [\"nnUNet_raw\", \"nnUNet_preprocessed\", \"nnUNet_results\"]:\n",
    "    print(\"export \" + var_name + \"=\" + os.environ[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# Ressource request on nora\n",
    "\n",
    "--time=2-0 --nodelist=loki --gpus-per-node=2  --cpus-per-task=16 --mem=64G\n",
    "\n",
    "source /software/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate segfm3d_2\n",
    "cd /nfs/norasys/notebooks/camaret/segfm3d_nora_team\n",
    "/software/inetaccess/inetaccess camaret\n",
    "\n",
    "export TORCH_COMPILE_DISABLE=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using nninteractive plans :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnUNetv2_extract_fingerprint -d 5 --verify_dataset_integrity\n",
    "\n",
    "\n",
    "# a) using ResEnc plans : \n",
    "nnUNetv2_plan_experiment -d 5 -pl nnUNetPlannerResEncL\n",
    "\n",
    "# b) using plans from nnInteractive_v1.0 :\n",
    "# cp nnInteractive_v1.0/plans.json $nnUNet_preprocessed/DatasetXXX_XXX/nnUNetResEncUNetLPlans_noResampling.json\n",
    "# in nnUNetResEncUNetLPlans_noResampling.json :\n",
    "# change the \"dataset_name\" field to the current one\n",
    "# change the \"resampling...\" fields to another method since we cannot access \"no_resampling_hack\" (e.g. \"resample_data_or_seg_to_shape\")\n",
    "# add a method 3d_fullres_ps192_bs1 that sets batch size = 1 since we are gpu poor \n",
    "\n",
    "# preprocess the dataset\n",
    "nnUNetv2_preprocess -d 5 -np 12 -plans_name nnUNetResEncUNetLPlans_noResampling -c 3d_fullres_ps192_bs1\n",
    "\n",
    "\n",
    "# define a custom trainer in  nnUNet/nnunetv2/training/nnUNetTrainer/CustomTrainer.py\n",
    "# train using the custom trainer with our preprocessing steps\n",
    "nnUNetv2_train 5 3d_fullres_ps192 0 -p nnUNetResEncUNetLPlans_noResampling -tr CustomTrainer\n",
    "# additional args : \n",
    "--num_gpus 1 -pretrained_weights /nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/checkpoints/nnInteractive_v1.0/fold_0/checkpoint_final.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_results/Dataset005_AMOS/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs1/fold_0/checkpoint_final.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[32m     16\u001b[39m model_path = os.path.join(os.environ[\u001b[33m\"\u001b[39m\u001b[33mnnUNet_results\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mDataset005_AMOS/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitialize_from_trained_model_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/norasys/notebooks/camaret/nnInteractive/nnInteractive/inference/inference_session.py:671\u001b[39m, in \u001b[36mnnInteractiveInferenceSession.initialize_from_trained_model_folder\u001b[39m\u001b[34m(self, model_training_output_dir, use_fold, checkpoint_name)\u001b[39m\n\u001b[32m    668\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fldrs) == \u001b[32m1\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAttempted to infer fold but there is != 1 fold_ folders: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfldrs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    669\u001b[39m     fold_folder = fldrs[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_training_output_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    673\u001b[39m trainer_name = checkpoint[\u001b[33m'\u001b[39m\u001b[33mtrainer_name\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    674\u001b[39m configuration_name = checkpoint[\u001b[33m'\u001b[39m\u001b[33minit_args\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mconfiguration\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/anaconda3/envs/segfm3d_2/lib/python3.12/site-packages/torch/serialization.py:1425\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/anaconda3/envs/segfm3d_2/lib/python3.12/site-packages/torch/serialization.py:751\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/anaconda3/envs/segfm3d_2/lib/python3.12/site-packages/torch/serialization.py:732\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_results/Dataset005_AMOS/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs1/fold_0/checkpoint_final.pth'"
     ]
    }
   ],
   "source": [
    "# cp nnInteractive_v1.0/inference_session_class.json to $nnUNet_results/DatasetXXX_XXX/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs1\n",
    "\n",
    "# weights are ready to be picked by the nnInteractive.inference.inference_session class\n",
    "import torch\n",
    "from nnInteractive.inference.inference_session import nnInteractiveInferenceSession\n",
    "session = nnInteractiveInferenceSession(\n",
    "    device=torch.device(\"cpu\"),  # Set inference device\n",
    "    use_torch_compile=False,  # Experimental: Not tested yet\n",
    "    verbose=False,\n",
    "    torch_n_threads=1,  # Use available CPU cores\n",
    "    do_autozoom=True,  # Enables AutoZoom for better patching\n",
    "    use_pinned_memory=True,  # Optimizes GPU memory transfers\n",
    ")\n",
    "\n",
    "# Load the trained model\n",
    "model_path = os.path.join(os.environ[\"nnUNet_results\"], \"Dataset005_AMOS/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs1\")\n",
    "session.initialize_from_trained_model_folder(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the trained model on the segfm3d task : \n",
    "python scripts/eval.py -ca 0 -m nnint_custom --checkpoint_path /nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_results/Dataset005_AMOS/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_results/Dataset005_AMOS/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs1/inference_session_class.json\n",
    "/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/nnUNet_results/Dataset005_AMOS/CustomTrainer__nnUNetResEncUNetLPlans_noResampling__3d_fullres_ps192_bs/inference_session_class.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network architecture with 8 input channels\n",
      "Model Info:\n",
      "model_type: ResidualEncoderUNet\n",
      "model_module: dynamic_network_architectures.architectures.unet\n",
      "num_parameters: 102355818\n",
      "input_channels: 1\n",
      "output_classes: 2\n",
      "configuration_name: 3d_fullres_ps192_bs1\n",
      "network_arch_class_name: dynamic_network_architectures.architectures.unet.ResidualEncoderUNet\n",
      "network_arch_init_kwargs: {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}\n",
      "network_arch_init_kwargs_req_import: ['conv_op', 'norm_op', 'dropout_op', 'nonlin']\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Also possible to avoid the nnInteractive class alltogether\n",
    "\n",
    "from nnunetv2.utilities.label_handling.label_handling import determine_num_input_channels\n",
    "from nnunetv2.utilities.find_class_by_name import recursive_find_python_class\n",
    "\n",
    "from nnunetv2.utilities.plans_handling.plans_handler import PlansManager, ConfigurationManager\n",
    "from batchgenerators.utilities.file_and_folder_operations import load_json, join, subdirs\n",
    "from nnInteractive.trainer.nnInteractiveTrainer import nnInteractiveTrainer_stub\n",
    "\n",
    "import nnInteractive\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_training_output_dir = model_path\n",
    "dataset_json = load_json(join(model_training_output_dir, 'dataset.json'))\n",
    "plans = load_json(os.path.join(model_training_output_dir, 'plans.json'))\n",
    "plans_manager = PlansManager(plans)\n",
    "checkpoint = torch.load(os.path.join(model_training_output_dir,\"fold_0/checkpoint_final.pth\"), map_location=device, weights_only=False)\n",
    "\n",
    "configuration_name = checkpoint['init_args']['configuration']\n",
    "\n",
    "parameters = checkpoint['network_weights']\n",
    "\n",
    "configuration_manager = plans_manager.get_configuration(configuration_name)\n",
    "\n",
    "trainer_name = checkpoint['trainer_name']\n",
    "\n",
    "num_input_channels = determine_num_input_channels(plans_manager, configuration_manager, dataset_json)\n",
    "\n",
    "\n",
    "trainer_class = recursive_find_python_class(join(nnInteractive.__path__[0], \"trainer\"),\n",
    "                                            trainer_name, 'nnInteractive.trainer')\n",
    "if trainer_class is None:\n",
    "    print(f'Unable to locate trainer class {trainer_name} in nnInteractive.trainer. '\n",
    "                        f'Please place it there (in any .py file)!')\n",
    "    print('Attempting to use default nnInteractiveTrainer_stub. If you encounter errors, this is where you need to look!')\n",
    "    trainer_class = nnInteractiveTrainer_stub\n",
    "\n",
    "network = trainer_class.build_network_architecture(\n",
    "    configuration_manager.network_arch_class_name,\n",
    "    configuration_manager.network_arch_init_kwargs,\n",
    "    configuration_manager.network_arch_init_kwargs_req_import,\n",
    "    num_input_channels,\n",
    "    plans_manager.get_label_manager(dataset_json).num_segmentation_heads,\n",
    "    enable_deep_supervision=False\n",
    ").to(device)\n",
    "network.load_state_dict(parameters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_info = {\n",
    "    \"model_type\": type(network).__name__,\n",
    "    \"model_module\": type(network).__module__,\n",
    "    \"num_parameters\": sum(p.numel() for p in network.parameters()),\n",
    "    \"input_channels\": num_input_channels,\n",
    "    \"output_classes\": plans_manager.get_label_manager(dataset_json).num_segmentation_heads,\n",
    "    \"configuration_name\": configuration_name,\n",
    "    \"network_arch_class_name\": configuration_manager.network_arch_class_name,\n",
    "    \"network_arch_init_kwargs\": configuration_manager.network_arch_init_kwargs,\n",
    "    \"network_arch_init_kwargs_req_import\": configuration_manager.network_arch_init_kwargs_req_import\n",
    "}\n",
    "\n",
    "print(\"Model Info:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"Model loaded successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segfm3d_2",
   "language": "python",
   "name": "segfm3d_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
