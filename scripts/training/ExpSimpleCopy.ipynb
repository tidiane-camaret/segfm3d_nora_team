{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_grad_enabled(False)  # Disable gradient calculation for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_segfm-robin/repos/segfm3d-nora')\n",
    "sys.path.append('/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_segfm-robin/repos/nnunetv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"DATA_DIR\": \"/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data\",\n",
    "    \"RESULTS_DIR\": \"/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/results\",\n",
    "    \"SAM_CKPT_PATH\": \"/nfs/norasys/notebooks/camaret/SAM-Med3D/ckpt/sam_med3d_turbo_bbox_cvpr.pth\",\n",
    "    \"SAM_REPO_DIR\": \"/nfs/norasys/notebooks/camaret/SAM-Med3D\",\n",
    "    \"ONNX_MODEL_PATH\": \"/nfs/norasys/notebooks/camaret/model_inference/models/sammed3d.onnx\",\n",
    "    \"NNINT_CKPT_DIR\": \"/nfs/norasys/notebooks/camaret/model_checkpoints/nnint\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from nnInteractive.inference.inference_session import nnInteractiveInferenceSession\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "args_for_network = {\n",
    "    \"arch_class_name\": \"dynamic_network_architectures.architectures.unet.ResidualEncoderUNet\",\n",
    "    \"arch_kwargs\": {\n",
    "        \"n_stages\": 6,\n",
    "        \"features_per_stage\": [32, 64, 128, 256, 320, 320],\n",
    "        \"conv_op\": \"torch.nn.modules.conv.Conv3d\",\n",
    "        \"kernel_sizes\": [\n",
    "            [3, 3, 3],\n",
    "            [3, 3, 3],\n",
    "            [3, 3, 3],\n",
    "            [3, 3, 3],\n",
    "            [3, 3, 3],\n",
    "            [3, 3, 3],\n",
    "        ],\n",
    "        \"strides\": [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]],\n",
    "        \"n_blocks_per_stage\": [1, 3, 4, 6, 6, 6],\n",
    "        \"n_conv_per_stage_decoder\": [1, 1, 1, 1, 1],\n",
    "        \"conv_bias\": True,\n",
    "        \"norm_op\": \"torch.nn.modules.instancenorm.InstanceNorm3d\",\n",
    "        \"norm_op_kwargs\": {\"eps\": 1e-05, \"affine\": True},\n",
    "        \"dropout_op\": None,\n",
    "        \"dropout_op_kwargs\": None,\n",
    "        \"nonlin\": \"torch.nn.LeakyReLU\",\n",
    "        \"nonlin_kwargs\": {\"inplace\": True},\n",
    "    },\n",
    "    \"arch_kwargs_req_import\": [\"conv_op\", \"norm_op\", \"dropout_op\", \"nonlin\"],\n",
    "    \"input_channels\": 8,\n",
    "    \"output_channels\": 2,\n",
    "    \"allow_init\": True,\n",
    "    \"deep_supervision\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from nnunetv2.utilities.get_network_from_plans import get_network_from_plans\n",
    "network = get_network_from_plans(**args_for_network).cuda()\n",
    "orig_checkpoint_dir = '/nfs/norasys/notebooks/camaret/model_checkpoints/nnint/nnInteractive_v1.0/'\n",
    "newer_checkpoint_dir = \"/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_segfm-robin/data/model-checkpoints/try_from_nb_less_augment/\"\n",
    "if os.path.exists(newer_checkpoint_dir):\n",
    "    chkpt_dict = torch.load(os.path.join(newer_checkpoint_dir, 'fold_0/checkpoint_final.pth'), weights_only=False)\n",
    "else:\n",
    "    chkpt_dict = torch.load(os.path.join(orig_checkpoint_dir, 'fold_0/checkpoint_final.pth'), weights_only=False)\n",
    "\n",
    "network.load_state_dict(chkpt_dict['network_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%aimport src.training.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from batchgeneratorsv2.transforms.spatial.mirroring import MirrorTransform\n",
    "from batchgeneratorsv2.transforms.spatial.spatial import SpatialTransform\n",
    "from batchgeneratorsv2.transforms.utils.compose import ComposeTransforms\n",
    "from batchgeneratorsv2.transforms.utils.deep_supervision_downsampling import (\n",
    "    DownsampleSegForDSTransform,\n",
    ")\n",
    "from batchgeneratorsv2.transforms.utils.random import RandomTransform\n",
    "from batchgeneratorsv2.transforms.utils.remove_label import RemoveLabelTansform\n",
    "\n",
    "from src.training.transforms import AddSegToImageTransform\n",
    "from src.training.transforms import NormalizeSingleImageTransform\n",
    "from src.training.transforms import AddBBoxAndEmptyChannelsSingleClassTransform\n",
    "from src.training.transforms import MONAIRandSpatialTransform\n",
    "from src.training.transforms import MONAIFixedSpatialTransform\n",
    "\n",
    "\n",
    "only_2d_bbox = False\n",
    "\n",
    "test_transform = ComposeTransforms(\n",
    "    [\n",
    "        NormalizeSingleImageTransform(),\n",
    "        MONAIFixedSpatialTransform(),\n",
    "        RemoveLabelTansform(segmentation_channels=None, label_value=-1, set_to=0),\n",
    "        AddBBoxAndEmptyChannelsSingleClassTransform(only_2d_bbox=only_2d_bbox),\n",
    "        AddSegToImageTransform(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# let's make very little augmentation\n",
    "train_transform = ComposeTransforms(\n",
    "    [\n",
    "        NormalizeSingleImageTransform(),\n",
    "        # MONAIRandSpatialTransform(\n",
    "        #     rotate_range=(0.025 * np.pi * 2, 0.025 * np.pi * 2, 0.025 * np.pi * 2),\n",
    "        #     scale_range=(0.2, 0.2, 0.2),\n",
    "        #     prob_affine=0.5,\n",
    "        # ),\n",
    "        MONAIFixedSpatialTransform(),\n",
    "        # RandomTransform(\n",
    "        #     apply_probability=0.1,\n",
    "        #     transform=GaussianNoiseTransform(\n",
    "        #         noise_variance=(0, 0.1), p_per_channel=1, synchronize_channels=True\n",
    "        #     ),\n",
    "        # ),\n",
    "        # RandomTransform(\n",
    "        #     apply_probability=0.2,\n",
    "        #     transform=GaussianBlurTransform(\n",
    "        #         blur_sigma=(0.5, 1.0),\n",
    "        #         benchmark=True,\n",
    "        #         synchronize_channels=False,\n",
    "        #         synchronize_axes=False,\n",
    "        #         p_per_channel=0.5,\n",
    "        #     ),\n",
    "        # ),\n",
    "        # MirrorTransform(allowed_axes=(0, 1, 2)),\n",
    "        RemoveLabelTansform(segmentation_channels=None, label_value=-1, set_to=0),\n",
    "        DownsampleSegForDSTransform(\n",
    "            ds_scales=[\n",
    "                [1.0, 1.0, 1.0],\n",
    "                [0.5, 0.5, 0.5],\n",
    "                [0.25, 0.25, 0.25],\n",
    "                [0.125, 0.125, 0.125],\n",
    "                [0.0625, 0.0625, 0.0625],\n",
    "            ]\n",
    "        ),\n",
    "        AddBBoxAndEmptyChannelsSingleClassTransform(only_2d_bbox=only_2d_bbox),\n",
    "        AddSegToImageTransform(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from src.training.npzdataset import NPZPytorchDataset, NPZDataset\n",
    "from src.training.utils import fast_ids_to_deterministic_floats\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "parent_folder = '/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/3D_train_npz_random_10percent_16G/'\n",
    "parent_save_folder = '/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_incontext/SegFM3D/data/own-preproc/'\n",
    "\n",
    "all_npz_file_paths = glob(os.path.join(parent_folder, '**/*.npz'), recursive=True)\n",
    "to_exclude = ['Ultrasound/US_Low-limb-Leg/US_Low-limb-Leg07.npz',\n",
    "       'Ultrasound/US_Low-limb-Leg/US_Low-limb-Leg24.npz',\n",
    "       'Ultrasound/US_Low-limb-Leg/US_Low-limb-Leg37.npz',\n",
    "       'CT/CT_Abdomen1K/CT_Abdomen1K_Case_00931.npz',\n",
    "       'Microscopy/Microscopy_cremi/Microscopy_cremi_002_sc.npz',\n",
    "       'Microscopy/Microscopy_cremi/Microscopy_cremi_000_sc.npz',\n",
    "       'Microscopy/Microscopy_cremi/Microscopy_cremi_001_sc.npz']\n",
    "\n",
    "\n",
    "identifiers = np.array([f.replace(parent_folder, \"\") for f in all_npz_file_paths])\n",
    "identifiers = np.array([f for f in identifiers if f not in to_exclude])\n",
    "\n",
    "train_mask = fast_ids_to_deterministic_floats(identifiers) < 0.8\n",
    "train_files = identifiers[train_mask]\n",
    "test_files = identifiers[~train_mask]\n",
    "dataset_tr = NPZDataset(parent_folder, parent_save_folder, train_files)\n",
    "dataset_val = NPZDataset(parent_folder, parent_save_folder, test_files)\n",
    "train_set = NPZPytorchDataset(\n",
    "    dataset_tr, transform=train_transform)\n",
    "\n",
    "test_set = NPZPytorchDataset(\n",
    "    dataset_val, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "n_jobs = int(os.environ['SLURM_CPUS_PER_TASK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=n_jobs,\n",
    "    batch_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "test_set = NPZPytorchDataset(\n",
    "    dataset_val, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=n_jobs,\n",
    "    batch_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm, trange\n",
    "import torch\n",
    "from src.training.model_wrap import ModelPrevSegAndClickWrapper\n",
    "from src.training.utils import defer_keysignal_with_grad\n",
    "\n",
    "wrapped_network = ModelPrevSegAndClickWrapper(network, n_max_clicks=1)\n",
    "\n",
    "optim_network = torch.optim.AdamW(\n",
    "    wrapped_network.parameters(), lr=3e-4, weight_decay=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import shutil\n",
    "out_dir = '/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_segfm-robin/data/model-checkpoints/try_from_nb_no_augment/'#'/nfs/data/nii/data1/Analysis/GPUnet/ANALYSIS_segfm-robin/data/model-checkpoints/try_from_nb_all_data_competition_bbox/'\n",
    "try:\n",
    "    shutil.copytree(orig_checkpoint_dir, out_dir)\n",
    "except FileExistsError:\n",
    "    print(f\"path {out_dir} exists already, fine\")\n",
    "trained_chkpt_path = os.path.join(out_dir, 'fold_0/checkpoint_final.pth')\n",
    "assert os.path.exists(trained_chkpt_path)\n",
    "\n",
    "\n",
    "trained_chkpt = deepcopy(chkpt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "accumulate_batch_size = 8\n",
    "n_batches_accumulate = accumulate_batch_size // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from src.training.utils import compute_binary_dsc\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "n_epochs = 25\n",
    "moving_dsc = None\n",
    "all_mean_dscs = []\n",
    "i_batch = 0\n",
    "optim_network.zero_grad()\n",
    "for i_epoch in trange(n_epochs):\n",
    "    epoch_mean_dscs = []\n",
    "    for batch in (pbar := tqdm(train_loader)):\n",
    "        with defer_keysignal_with_grad():\n",
    "            targets = batch[\"segmentation\"][0][:,0].long().cuda()\n",
    "            out = wrapped_network(batch[\"image\"].cuda())\n",
    "            # assuming deep supervision\n",
    "            pred = out[0]\n",
    "            assert pred[:,0].shape == targets.shape\n",
    "            cent = torch.nn.functional.cross_entropy(pred, targets)\n",
    "            binary_pred = torch.sigmoid(torch.diff(pred, dim=1)[:,0])\n",
    "            assert binary_pred.shape == targets.shape\n",
    "            eps = 1e-3\n",
    "            intersect = torch.sum(binary_pred * targets, dim=(1,2,3))\n",
    "            sum_pred = torch.sum(binary_pred, dim=(1,2,3))\n",
    "            sum_targets = torch.sum(targets, dim=(1,2,3))\n",
    "            mean_dsc = torch.mean((2 * intersect + eps) / (sum_pred + sum_targets + eps))\n",
    "            loss = cent + 10 * (1 - mean_dsc)\n",
    "            loss.backward()\n",
    "            i_batch += 1\n",
    "            if torch.isfinite(loss).item() and ((i_batch % n_batches_accumulate) == 0):\n",
    "                optim_network.step()\n",
    "                optim_network.zero_grad()\n",
    "            elif not torch.isfinite(loss).item():\n",
    "                print(\"loss not finite, not updating!\")\n",
    "                optim_network.zero_grad()\n",
    "            else:\n",
    "                pass\n",
    "        epoch_mean_dscs.append(mean_dsc.item())\n",
    "        if torch.isfinite(loss).item():\n",
    "            moving_dsc = mean_dsc if moving_dsc is None else (moving_dsc * 0.98 + mean_dsc * 0.02)\n",
    "        pbar.set_postfix(dict(moving_dsc=moving_dsc.item()))\n",
    "        print(mean_dsc.item())\n",
    "        print(cent.item())\n",
    "        print()\n",
    "    print(\"mean dsc\", np.nanmean(epoch_mean_dscs))\n",
    "    all_mean_dscs.extend(epoch_mean_dscs)\n",
    "    \n",
    "    print(f\"Epoch {i_epoch}\")\n",
    "    if torch.isfinite(loss).item():\n",
    "        trained_chkpt['network_weights'] = wrapped_network.orig_network.state_dict()\n",
    "        torch.save(trained_chkpt, trained_chkpt_path)\n",
    "        print(f\"Checkpoint saved to {trained_chkpt_path}\")\n",
    "\n",
    "    test_results = []\n",
    "    for batch in (pbar := tqdm(test_loader)):\n",
    "        targets = batch[\"segmentation\"][:, 0].long().cuda()\n",
    "        out = wrapped_network(batch[\"image\"].cuda())\n",
    "        # assuming deep supervision\n",
    "        pred = out[0]\n",
    "        assert pred[:, 0].shape == targets.shape\n",
    "        cent = torch.nn.functional.cross_entropy(pred, targets)\n",
    "        binary_pred = torch.sigmoid(torch.diff(pred, dim=1)[:, 0])\n",
    "        assert binary_pred.shape == targets.shape\n",
    "        eps = 1e-3\n",
    "        intersect = torch.sum(binary_pred * targets, dim=(1, 2, 3))\n",
    "        sum_pred = torch.sum(binary_pred, dim=(1, 2, 3))\n",
    "        sum_targets = torch.sum(targets, dim=(1, 2, 3))\n",
    "        mean_dsc = torch.mean((2 * intersect + eps) / (sum_pred + sum_targets + eps))\n",
    "        test_results.append(\n",
    "            dict(\n",
    "                hard_dsc=compute_binary_dsc((binary_pred > 0.5), targets),\n",
    "                soft_dsc=((2 * intersect + eps) / (sum_pred + sum_targets + eps)).cpu().numpy().mean(),\n",
    "                cent=cent.item()\n",
    "            )\n",
    "        )\n",
    "    display(pd.DataFrame(test_results).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# look at examples etc.\n",
    "# now try click changes, grad clip? gradient accum?\n",
    "# different sampling?\n",
    "# old loki\n",
    "# http://10.217.3.189:8888/lab?token=7fe7920caa53ef1ca025abdc8c4fdaedc532ecf340635f2f\n",
    "\n",
    "\n",
    "# nero\n",
    "# http://10.231.0.162:8888/lab?token=1e5d7331c18592a8cb58ced34b88232869e16ea21a98b4c9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "test_results = []\n",
    "for batch in (pbar := tqdm(test_loader)):\n",
    "    targets = batch[\"segmentation\"][:, 0].long().cuda()\n",
    "    out = wrapped_network(batch[\"image\"].cuda())\n",
    "    # assuming deep supervision\n",
    "    pred = out[0]\n",
    "    assert pred[:, 0].shape == targets.shape\n",
    "    cent = torch.nn.functional.cross_entropy(pred, targets)\n",
    "    binary_pred = torch.sigmoid(torch.diff(pred, dim=1)[:, 0])\n",
    "    assert binary_pred.shape == targets.shape\n",
    "    eps = 1e-3\n",
    "    intersect = torch.sum(binary_pred * targets, dim=(1, 2, 3))\n",
    "    sum_pred = torch.sum(binary_pred, dim=(1, 2, 3))\n",
    "    sum_targets = torch.sum(targets, dim=(1, 2, 3))\n",
    "    mean_dsc = torch.mean((2 * intersect + eps) / (sum_pred + sum_targets + eps))\n",
    "    test_results.append(\n",
    "        dict(\n",
    "            hard_dsc=compute_binary_dsc((binary_pred > 0.5), targets),\n",
    "            soft_dsc=((2 * intersect + eps) / (sum_pred + sum_targets + eps)).cpu().numpy().mean(),\n",
    "            cent=cent.item()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "finite_dscs = np.array(all_mean_dscs)[np.isfinite(np.array(all_mean_dscs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(np.correlate(finite_dscs, np.ones(100)/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "display(pd.DataFrame(test_results).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "display(pd.DataFrame(test_results).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segfm3d_2",
   "language": "python",
   "name": "segfm3d_2"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
